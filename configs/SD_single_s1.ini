# config file for main_single (trainer)

[io]
dir_out =   D:/jema2085/data/Belgica_Bank/results/SD/s1-jan
            D:/jema2085/data/Belgica_Bank/results/SD/s1-feb
            D:/jema2085/data/Belgica_Bank/results/SD/s1-mar
            D:/jema2085/data/Belgica_Bank/results/SD/s1-nov
            D:/jema2085/data/Belgica_Bank/results/SD/s1-dec

fname_csv = D:/jema2085/data/Belgica_Bank/results/BB_IO-SD-s1-jan.csv
            D:/jema2085/data/Belgica_Bank/results/BB_IO-SD-s1-feb.csv
            D:/jema2085/data/Belgica_Bank/results/BB_IO-SD-s1-mar.csv
            D:/jema2085/data/Belgica_Bank/results/BB_IO-SD-s1-nov.csv
            D:/jema2085/data/Belgica_Bank/results/BB_IO-SD-s1-dec.csv

[model]
num_streams = 1
num_classes = 4
pretrained = True

[loss]
loss = cross_entropy
alpha = 0.5
gamma = 5

[datamodule]
n_samples_per_input = 200
crop_len = 61_440
seed = 1
mean = -26.23734114, -14.03884421, -26.16954528, -13.93613932, -27.05791304, -14.69861306, -26.670155, -14.34679455, -26.34163708, -13.93410375
std = 6.48612738, 4.5417054, 6.39081166, 4.4576594, 5.9985457, 4.43712224, 6.18186522, 4.53636641, 6.08382612, 4.31270138

[train]
fine_tune = False
ignore_index = 4
min_epochs = 10
max_epochs = 200
patience = 20
reduce_lr_patience = 5
batch_size = 32
lr=1e-5
reload_every_n_epochs = 0